{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07fb77f3",
   "metadata": {},
   "source": [
    "# ğŸŒŠ Deep Dive Into Isolation Forest\n",
    "> **ì‘ì„±ì : ì˜¤ìˆ˜ì§€ (2022020660)**\n",
    "\n",
    "ì•ˆë…•í•˜ì„¸ìš”, ê³ ë ¤ëŒ€í•™êµ ì‚°ì—…ê²½ì˜ê³µí•™ë¶€ DSBA ì—°êµ¬ì‹¤ ì„ì‚¬ê³¼ì • ì˜¤ìˆ˜ì§€ì…ë‹ˆë‹¤.  \n",
    "ì´ë²ˆ ë…¸íŠ¸ë¶ íŠœí† ë¦¬ì–¼ì—ì„  Model-based Anomaly Detection ë°©ë²•ë¡ , ê·¸ ì¤‘ì—ì„œë„ **`Isolation Forest`**ì— ëŒ€í•´ ì½”ë“œë¥¼ í†µí•´ ì•Œì•„ë³¼ ì˜ˆì •ì…ë‹ˆë‹¤. (ğŸ” Anomaly Detectionì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ë‚´ìš©ì€ [ìœ íŠœë¸Œ íŠœí† ë¦¬ì–¼ ì˜ìƒ](https://youtu.be/XshinhpMrLQ)ì„ ì°¸ê³ í•´ì£¼ì„¸ìš”.)\n",
    "\n",
    "Isolation ForestëŠ” ë§¤ìš° ì§ê´€ì ì´ê³ , ì´ìƒì¹˜ íƒì§€ ëŒ€íšŒì—ì„œ ì•„ì§ê¹Œì§€ë„ ë§ì´ ì‚¬ìš©ë˜ê³  ìˆëŠ” ë°©ë²•ë¡ ì¸ë°ìš”! ì—¬ëŸ¬ ê°œì˜ Decision Treeë¥¼ ì§€ì†ì ìœ¼ë¡œ ë¶„ê¸°ì‹œí‚¤ë©´ì„œ ëª¨ë“  ë°ì´í„° ê´€ì¸¡ì¹˜ì˜ ê³ ë¦½ ì •ë„ ì—¬ë¶€ì— ë”°ë¼ ì´ìƒì¹˜ë¥¼ íŒë³„í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì‰½ê²Œ ìƒê°í•´ë³´ìë©´ ì´ìƒì¹˜ ë°ì´í„°ì¼ìˆ˜ë¡ ë‹¤ë¥¸ ì •ìƒ ë°ì´í„°ì™€ ë‹¤ë¥¸ íŠ¹ì„±ì„ ëŒí…Œë‹ˆ ë¹¨ë¦¬ ê³ ë¦½ë  ê²ƒì´ê³ , ì •ìƒ ë°ì´í„°ì¼ìˆ˜ë¡ ì„œë¡œì„œë¡œ ë¹„ìŠ·ë¹„ìŠ·í• í…Œë‹ˆ ëŠ¦ê²Œ ê³ ë¦½ë˜ê² ì£ ?! ì¦‰, **íŠ¹ì • ë°ì´í„°ê°€ ê³ ë¦½ë˜ëŠ” leaf nodeê¹Œì§€ì˜ ê±°ë¦¬**ë¥¼ `Anomaly Score`ë¡œ ì •ì˜í•˜ê³ , ì¼ì° ê³ ë¦½ë ìˆ˜ë¡, ì¦‰ root nodeë¡œë¶€í„° leaf nodeê¹Œì§€ì˜ í‰ê·  ê±°ë¦¬ê°€ ì§§ì„ìˆ˜ë¡ anomaly scoreê°€ ë†’ì•„ì§€ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ê·¼ë° ìˆ˜ì—…ì„ ë“¤ìœ¼ë©´ì„œë„, ìœ íŠœë¸Œ ë™ì˜ìƒì„ ë§Œë“¤ë©´ì„œë„ ì „ í•œ ê°€ì§€ ì˜ë¬¸ì ì´ ë“¤ì—ˆìŠµë‹ˆë‹¤. ë¶„ê¸°ì˜ ê¸°ì¤€ì´ ë˜ëŠ” Attributeë¥¼ ëœë¤í•˜ê²Œ ì„ íƒí•˜ì§€ ì•Šìœ¼ë©´ ì–´ë–¨ê¹Œìš”?  Isolation ForestëŠ” Decision Treeë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ë°©ë²•ë¡ ì´ê³ , Decision Treeì˜ ë¶„ê¸° ê¸°ì¤€ì€ Information gain, Gini Impurity, Chi-Square ë“± ì—¬ëŸ¬ê°€ì§€ê°€ ìˆëŠ”ë§Œí¼ ë§Œì•½ ëœë¤í•˜ê²Œ í•˜ì§€ ì•Šìœ¼ë©´ ê²°ê³¼ê°€ ë‹¬ë¼ì§€ì§€ ì•Šì„ê¹Œìš”?\n",
    "\n",
    "ê·¸ëŸ¬ê¸° ìœ„í•´ì„œ ì¼ë‹¨ (1) Isolation Forestë¥¼ Scratchë¶€í„° êµ¬í˜„í•œ ë ˆí¬ë¥¼ pseudo codeì™€ ëŒ€ì¡°í•´ê°€ë©° line by lineìœ¼ë¡œ ì´í•´ë¥¼ í•˜ê³ , (2) Information Gainì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ê¸°í•˜ëŠ” ì½”ë“œë¥¼ ì¶”ê°€í•œ ë‹¤ìŒ (3) ë‘ ë°©ì‹ê°„ ì„±ëŠ¥ ì°¨ì´ë¥¼ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤ ğŸ˜€\n",
    "\n",
    "<img src=\"images/if.png\" width=\"550\">\n",
    "\n",
    "**ğŸ“Œ ì´ë²ˆ íŠœí† ë¦¬ì–¼ì˜ ëª©í‘œ**\n",
    ">1. Isolation Forest from Scratch\n",
    ">2. Isolation Forest without Randomness from Scratch\n",
    ">3. 1, 2ë²ˆ ê°„ ì„±ëŠ¥ ë¹„êµ\n",
    "\n",
    "**ğŸ“Œ Reference**\n",
    "- https://github.com/mgckind/iso_forest\n",
    "- https://github.com/sahandha/eif\n",
    "- https://hongl.tistory.com/150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfcee65",
   "metadata": {},
   "source": [
    "## ğŸ›  í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e05b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import easydict\n",
    "import wandb\n",
    "import nltk\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import pickle\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "import copy\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.set_style(style=\"whitegrid\")\n",
    "sb.set_color_codes()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81db7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 1201):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e2b1f6",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ë°ì´í„° ì¤€ë¹„\n",
    "> Daconì—ì„œ ì—´ë¦° **`ì›”ê°„ ë°ì´ì½˜ ì‹ ìš©ì¹´ë“œ ì‚¬ê¸° ê±°ë˜ íƒì§€ AI ê²½ì§„ëŒ€íšŒ`**ì˜ ì‹ ìš©ì¹´ë“œ ê±°ë˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤! (ëŒ€íšŒì—ì„œ ì œê³µí•œ ë°ì´í„°ì˜ ì› ì¶œì²˜ëŠ” ëŒ€íšŒ ë°ì´í„° ì„¤ëª… íƒ­ì— ë‚˜ì™€ìˆìŠµë‹ˆë‹¤.) \n",
    "\n",
    "**1. í•™ìŠµ(Train) ë°ì´í„°ì…‹ (113842ê°œ)**  \n",
    "\n",
    "íŒŒì¼ëª…: train.csv  \n",
    "ì„¤ëª…: ì •ìƒ, ì‚¬ê¸° ê±°ë˜ì˜ ì—¬ë¶€ë¥¼ ì•Œ ìˆ˜ ì—†ëŠ”(ëŒ€ë¶€ë¶„ ì •ìƒ ê±°ë˜) ì‹ ìš© ì¹´ë“œ ë°ì´í„° (Unlabeled)  \n",
    "ID : ì‹ ìš© ì¹´ë“œ ê±°ë˜ ID  \n",
    "Column ('V1', 'V2', 'V3', ... ,'V30) : ë¹„ì‹ë³„í™”ëœ ì‹ ìš© ì¹´ë“œ ê±°ë˜ Feature  \n",
    "\n",
    "\n",
    "**2. ê²€ì¦(Validation) ë°ì´í„°ì…‹ (28462ê°œ)**   \n",
    "\n",
    "íŒŒì¼ëª…: val.csv  \n",
    "ì„¤ëª…: ì •ìƒ, ì‚¬ê¸° ê±°ë˜ì˜ ì—¬ë¶€ê°€ í¬í•¨ëœ ì‹ ìš© ì¹´ë“œ ë°ì´í„°\n",
    "ID : ì‹ ìš© ì¹´ë“œ ê±°ë˜ ID   \n",
    "Column ('V1', 'V2', 'V3', ... ,'V30) : ë¹„ì‹ë³„í™”ëœ ì‹ ìš© ì¹´ë“œ ê±°ë˜ Feature  \n",
    "Class : ì‹ ìš© ì¹´ë“œ ê±°ë˜ì˜ ì •ìƒ, ì‚¬ê¸° ì—¬ë¶€ (ì •ìƒ : 0, ì‚¬ê¸° : 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af074c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"./data/credit_card_fraud_detection/train.csv\")\n",
    "val_dataset = pd.read_csv(\"./data/credit_card_fraud_detection/val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa6f3ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.drop(columns=['ID'])\n",
    "val_dataset_label = val_dataset['Class']\n",
    "val_dataset_attributes = val_dataset.drop(columns=['Class', 'ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5199460b",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Isolation Forest from Scratch\n",
    "> ì½”ë“œëŠ” https://github.com/mgckind/iso_forest ì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. ë‹¤ë§Œ, ì½”ë“œì— ì£¼ì„ì´ ì—†ì–´ ì•Œê³ ë¦¬ì¦˜ì„ ì•Œê³  ì½”ë“œë¥¼ ë´ë„ ì´í•´ê°€ ì–´ë µìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ë³¸ ëª©ì°¨ëŠ” ìœ„ì˜ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹ ìš©ì¹´ë“œ ê±°ë˜ ë°ì´í„°ì…‹ì— ë§ëŠ” ì¶”ê°€ì ì¸ ë¦¬íŒ©í† ë§ ë° pseudo codeì™€ í•¨ê»˜ line by lineìœ¼ë¡œ í•¨ê»˜ ì´í•´í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47adb9f",
   "metadata": {},
   "source": [
    "### ğŸ” Node\n",
    "> Treeì˜ ê° Nodeì—ëŠ” ì–´ë–¤ ì •ë³´ê°€ í¬í•¨ë ê¹Œìš”?\n",
    "- ì—¬ê¸°ì„œ `External Node`ë€ ìì‹ ë…¸ë“œê°€ ì—†ëŠ” ë…¸ë“œ(ì¦‰, Leaf Node), `Internal Node`ë€ ì ì–´ë„ í•˜ë‚˜ì˜ ìì‹ ë…¸ë“œê°€ ìˆëŠ” ë…¸ë“œë¥¼ ëœ»í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f516cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, X, q, p, e, left, right, node_type = ''):\n",
    "        self.e = e  # í˜„ì¬ tree height\n",
    "        self.size = len(X) # ë°ì´í„°ì— í¬í•¨ëœ object ê°œìˆ˜\n",
    "        self.q = q  # split attribute\n",
    "        self.p = p  # split point\n",
    "        self.left = left  # í˜„ì¬ Nodeì˜ Left Node\n",
    "        self.right = right  # í˜„ì¬ Nodeì˜ Right Node\n",
    "        self.ntype = node_type  # í˜„ì¬ Nodeì˜ Type (External Node or Internal Node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e6655a",
   "metadata": {},
   "source": [
    "### ğŸ” iTree\n",
    "<img src=\"images/if_itree.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2af799fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class iTree(object):\n",
    "    def __init__(self, X, e, l):\n",
    "        self.e = e  # í˜„ì¬ tree height\n",
    "        self.X = X  # ë°ì´í„°\n",
    "        self.size = len(X) # ë°ì´í„°ì— í¬í•¨ëœ object ê°œìˆ˜\n",
    "        self.Q = list(X.columns)  # ë°ì´í„°ì˜ attributes\n",
    "        self.l = l  # ì¢…ë£Œ ì¡°ê±´ì— ì‚¬ìš©ë  treeì˜ height limit\n",
    "        self.p = None  # split point (max(values of q), min(values of q) ì¤‘ ëœë¤í•˜ê²Œ ì„ íƒë¨)\n",
    "        self.q = None  # split attribute (Qì—ì„œ ëœë¤í•˜ê²Œ ì„ íƒë¨)\n",
    "        self.exnodes = 0  # external node\n",
    "        self.root = self.make_tree(X, e, l)\n",
    "        \n",
    "\n",
    "    def make_tree(self, X, e, l, split_criteria='random'):\n",
    "        self.e = e\n",
    "        \n",
    "        # ì¢…ë£Œ ì¡°ê±´\n",
    "        # 1. í˜„ì¬ tree heightì´ ì‚¬ì „ ì§€ì •í•œ height limitì— ë„ë‹¬í•œ ê²½ìš°\n",
    "        # 2. leaf nodeì— ë°ì´í„°ê°€ í•œê°œë§Œ ë‚¨ê²¨ì§„ ê²½ìš°\n",
    "        if e >= l or len(X) <= 1:\n",
    "            left = None\n",
    "            right = None\n",
    "            self.exnodes += 1\n",
    "            return Node(X, self.q, self.p, e, left, right, node_type = 'exNode')\n",
    "        else:\n",
    "            # Splití•˜ëŠ” ê¸°ì¤€ì´ ë˜ëŠ” Attributeë¥¼ ë°ì´í„°ì˜ Attributes ì¤‘ì—ì„œ ëœë¤í•˜ê²Œ ì„ íƒ\n",
    "            self.q = random.choice(self.Q)\n",
    "            mini = X[:][self.q].min()\n",
    "            maxi = X[:][self.q].max()\n",
    "            if mini==maxi:\n",
    "                left = None\n",
    "                right = None\n",
    "                self.exnodes += 1\n",
    "                return Node(X, self.q, self.p, e, left, right, node_type = 'exNode' )\n",
    "            \n",
    "            # Split Pointë¥¼ min(values of q), max(values of q) ì¤‘ ëœë¤í•˜ê²Œ ì„ íƒ\n",
    "            self.p = random.uniform(mini, maxi)\n",
    "            \n",
    "            # qê°€ pë³´ë‹¤ ì‘ì€ ë°ì´í„°ë“¤ì€ left nodeë¡œ, qê°€ pë³´ë‹¤ ê°™ê±°ë‚˜ í° ë°ì´í„°ë“¤ì€ right nodeë¡œ ì§€ì •\n",
    "            # ìœ„ì™€ ê°™ì€ ê³¼ì •ë“¤ì„ ì¬ê·€ì ìœ¼ë¡œ ë¶„ê¸° ì§„í–‰\n",
    "            w = np.where(X[:][self.q] < self.p, True, False)\n",
    "            return Node(X, self.q, self.p, e,\\\n",
    "                        left=self.make_tree(X[w], e+1, l),\\\n",
    "                        right=self.make_tree(X[~w], e+1, l),\\\n",
    "                        node_type = 'inNode')\n",
    "\n",
    "    def get_node(self, path):\n",
    "        node = self.root\n",
    "        for p in path:\n",
    "            if p == 'L' : node = node.left\n",
    "            if p == 'R' : node = node.right\n",
    "        return node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9d8529",
   "metadata": {},
   "source": [
    "### ğŸ” iForest\n",
    "> ê·¸ëŸ¼ ì´ì œ ìœ„ì—ì„œ êµ¬ì¶•ëœ Isolation Treeë¥¼ ê°€ì§€ê³  ë³¸ê²©ì ìœ¼ë¡œ Forestë¥¼ êµ¬ì¶•í•´ë³´ê² ìŠµë‹ˆë‹¤! Isolation Forestë€ ë§ê·¸ëŒ€ë¡œ ì—¬ëŸ¬ Isolation Treeë¡œ êµ¬ì„±ëœ ìˆ²ì„ ëœ»í•©ë‹ˆë‹¤. ìœ„ì—ì„œ í™•ì¸í–ˆë‹¤ì‹¶ì´ ë­ë“ ì§€ ëœë¤í•˜ê²Œ ì„ íƒë˜ê³ , ëœë¤í•˜ê²Œ ë¶„ê¸°í•˜ë‹ˆê¹Œ í•˜ë‚˜ì˜ Treeë¡œ ì–»ì–´ì§„ Anomaly Scoreë¥¼ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šê² ì£ ..?! ê·¸ëŸ¬ë¯€ë¡œ ì—¬ëŸ¬ Treeë¥¼ í†µí•´ ì–»ì€ Anomaly Scoreë¥¼ ìµœì¢…ì ìœ¼ë¡œ í‰ê· ë‚´ì„œ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "<img src=\"images/if_iforest.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5415723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_factor(n) :\n",
    "    return 2.0*(np.log(n-1)+0.5772156649) - (2.0*(n-1.)/(n*1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ee49d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class iForest(object):\n",
    "    def __init__(self, X, ntrees, sample_size, limit=None):\n",
    "        self.ntrees = ntrees  # ëª‡ ê°œì˜ Treeë¡œ ìˆ²ì„ êµ¬ì„±í• ì§€ ê²°ì •\n",
    "        self.X = X\n",
    "        self.nobjs = len(X)\n",
    "        self.sample = sample_size  # ìƒ˜í”Œë§ ì‚¬ì´ì¦ˆ (ëª‡ ê°œì˜ ë°ì´í„°ë¥¼ ì´ìš©í•´ ê° treeë¥¼ í•™ìŠµí• ì§€)\n",
    "        self.Trees = []\n",
    "        self.limit = limit  # height limit (iTreeë¥¼ êµ¬ì¶•í•  ë•Œ ì¢…ë£Œ ì¡°ê±´ì— í™œìš©ë  ë³€ìˆ˜)\n",
    "        if limit is None:\n",
    "            self.limit = int(np.ceil(np.log2(self.sample)))\n",
    "        self.c = c_factor(self.sample)\n",
    "        # pseudo code #3 ~ #6\n",
    "        # ì‚¬ì „ ì„¤ì •í•œ Tree ê°œìˆ˜ì— ë”°ë¼ ê° Treeë³„ ëœë¤í•˜ê²Œ ë°ì´í„° ìƒ˜í”Œë§ í›„, iTree êµ¬ì¶•\n",
    "        for i in tqdm(range(self.ntrees), desc=\"Constructing Tree...\"):\n",
    "            ix = random.sample(range(self.nobjs), self.sample)\n",
    "            X_p = X.loc[ix]\n",
    "            self.Trees.append(iTree(X_p, 0, self.limit))\n",
    "\n",
    "    def compute_paths(self, X_in = None):\n",
    "        if X_in is None:\n",
    "            X_in = self.X\n",
    "        S = np.zeros(len(X_in))\n",
    "        for i in  tqdm(range(len(X_in)), desc=\"Computing path...\"):\n",
    "            h_temp = 0\n",
    "            for j in range(self.ntrees):\n",
    "                h_temp += PathFactor(X_in.loc[i], self.Trees[j]).path*1.0\n",
    "            \"\"\"\n",
    "            Anomaly Score ê³„ì‚°ì‹\n",
    "            Eh = ì „ì²´ Treeì— ëŒ€í•´ íŠ¹ì • Leaf Node(ë°ì´í„°)ê¹Œì§€ì˜ í‰ê·  ê¸¸ì´ \n",
    "            ë†’ì„ìˆ˜ë¡ ë°ì´í„°ë¥¼ ê³ ë¦½ì‹œí‚¤ëŠ”ë° ë§ì€ ë¶„ê¸°ê°€ í•„ìš” â†’ ì •ìƒë°ì´í„°ì¼ í™•ë¥  â¬†\n",
    "            ë‚®ì„ìˆ˜ë¡ ë°ì´í„°ë¥¼ ê³ ë¦½ì‹œí‚¤ëŠ”ë° ì ì€ ë¶„ê¸°ê°€ í•„ìš” â†’ ì´ìƒì¹˜ì¼ í™•ë¥  â¬†\n",
    "            \"\"\"\n",
    "            Eh = h_temp / self.ntrees\n",
    "            S[i] = 2.0**(-Eh/self.c)\n",
    "        return S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbea1e1",
   "metadata": {},
   "source": [
    "### ğŸ” Path Length\n",
    "> ì´ìƒì¹˜ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•´ì„  ê° Tree ë³„ ë°ì´í„°ê°€ ê³ ë¦½ë˜ê¸°ê¹Œì§€ì˜ í‰ê·  ê¸¸ì´ (ì¦‰, ë£¨íŠ¸ ë…¸ë“œë¡œë¶€í„° ë°ì´í„° ë…¸ë“œê¹Œì§€ì˜ ê±°ë¦¬)ë¥¼ ê³„ì‚°í•´ì•¼ í•©ë‹ˆë‹¤.    \n",
    "\n",
    "<img src=\"images/if_pathlength.png\" width=\"450\">\n",
    "\n",
    "\n",
    "> ğŸ’¡ íŠ¹íˆ ì²˜ìŒ ê°•ì˜ ìë£Œì—ì„œ pseudo codeë§Œ ë³´ì•˜ì„ ë• #1~#2ì´ ë¬´ì—‡ì„ ìœ„í•œ ê±´ì§€ ì´í•´ê°€ ì•ˆëëŠ”ë° **height limitì— ì˜í•´ ë¶„ê¸°ê°€ ì¤‘ë‹¨ë˜ì–´ ê³ ë ¤ë˜ì§€ ëª»í•œ ì‹¤ì§ˆì ì¸ depthë¥¼ ë°˜ì˜í•˜ê¸° ìœ„í•´** ê° ë°ì´í„° ë³„ë¡œ cê°’ì„ ë”í•´ì£¼ëŠ” ê±°ë¼ê³  í•©ë‹ˆë‹¤!  \n",
    "\n",
    "> ë§Œì•½ leaf nodeì— í¬í•¨ëœ ë°ì´í„°ê°€ 1ê°œë¼ë©´ ì™„ë²½íˆ ê³ ë¦½ëœ ê²ƒì´ë¯€ë¡œ c=1ë¡œ ë‘ê³ , 1ê°œë³´ë‹¤ í¬ë‹¤ë©´ height limitìœ¼ë¡œ ì¸í•´ ë” ì´ìƒ ë¶„ê¸°í•˜ì§€ ëª»í•œ ê²ƒì´ë‹ˆ ì•„ë˜ì™€ ê°™ì€ ì‹ìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ êµ¬í•œ cê°’ì„ ê° ë°ì´í„° ë³„ leaf nodeì˜ depthì— ë”í•´ì£¼ë©´ ê° ë°ì´í„° ë³„ í‰ê·  ê¸¸ì´ë¥¼ ê° Treeë³„ë¡œ ë³´ì •í•˜ëŠ” íš¨ê³¼ë¥¼ ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "<img src=\"images/if_c.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab1c5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathFactor(object):\n",
    "    def __init__(self, x, itree):\n",
    "        self.path_list=[]        \n",
    "        self.x = x\n",
    "        self.e = 0\n",
    "        self.path = self.find_path(itree.root)\n",
    "\n",
    "    def find_path(self,T):\n",
    "        if T.ntype == 'exNode':\n",
    "            # Case 1 : leaf nodeì— ë°ì´í„°ê°€ í•œê°œë§Œ ì¡´ì¬í•˜ëŠ” ì™„ì „íˆ ê³ ë¦½ëœ ìƒíƒœ\n",
    "            # Current Tree Pathë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™”\n",
    "            if T.size == 1: return self.e\n",
    "            # Case 2 : leaf nodeì— ë°ì´í„°ê°€ ë‘ê°œ ì´ìƒ ì¡´ì¬í•˜ëŠ” ì™„ì „íˆ ê³ ë¦½ë˜ì§€ ëª»í•œ ìƒíƒœ\n",
    "            # Current Tree Path + c_factor ë°˜í™˜\n",
    "            else:\n",
    "                self.e = self.e + c_factor(T.size)\n",
    "                return self.e\n",
    "        else:\n",
    "            a = T.q\n",
    "            self.e += 1\n",
    "            if self.x[a] < T.p:\n",
    "                self.path_list.append('L')\n",
    "                return self.find_path(T.left)\n",
    "            else:\n",
    "                self.path_list.append('R')\n",
    "                return self.find_path(T.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d40599",
   "metadata": {},
   "source": [
    "### ğŸ” ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75356797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(anomaly_score):\n",
    "    # Anomaly Distributionì„ ì‹œê°í™”\n",
    "    f, axes = plt.subplots(1, 1, figsize=(7, 7), sharex=True)\n",
    "    sb.distplot(anomaly_score, kde=True, color=\"b\", ax=axes, axlabel='anomaly score')\n",
    "        \n",
    "def show_result(anomaly_score, threshold=[0.5, 0.6, 0.7, 0.8, 0.9]):\n",
    "    f1_scores = {}\n",
    "    for t in threshold:\n",
    "        result = np.where(anomaly_score >= t, 1, 0)\n",
    "        f1_scores[t] = round(f1_score(val_dataset_label, result, average='macro'), 3)\n",
    "    for t in f1_scores.keys():\n",
    "        print(f'Threshold: {t} => Macro F1-Score: {f1_scores[t]}')\n",
    "    print(f'â­ï¸ Best F1-Score : {sorted(f1_scores.items(), reverse=True, key=lambda item: item[1])[0][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27262c84",
   "metadata": {},
   "source": [
    "- **tree ê°œìˆ˜ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c2faef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Number of ğŸŒ³ : 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3934037546cd45b18786e5c692479163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Constructing Tree...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed234cb1629464a84e263b69c76d538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing path...:   0%|          | 0/28462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5 => Macro F1-Score: 0.511\n",
      "Threshold: 0.6 => Macro F1-Score: 0.566\n",
      "Threshold: 0.7 => Macro F1-Score: 0.648\n",
      "Threshold: 0.8 => Macro F1-Score: 0.5\n",
      "Threshold: 0.9 => Macro F1-Score: 0.5\n",
      "â­ï¸ Best F1-Score : 0.648\n",
      "====================================================================================================\n",
      "Number of ğŸŒ³ : 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf04bdb99f64780805fcdb8a1d7b477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Constructing Tree...:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3621cf0d07a4455b9493094676348ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing path...:   0%|          | 0/28462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5 => Macro F1-Score: 0.508\n",
      "Threshold: 0.6 => Macro F1-Score: 0.561\n",
      "Threshold: 0.7 => Macro F1-Score: 0.545\n",
      "Threshold: 0.8 => Macro F1-Score: 0.5\n",
      "Threshold: 0.9 => Macro F1-Score: 0.5\n",
      "â­ï¸ Best F1-Score : 0.561\n",
      "====================================================================================================\n",
      "Number of ğŸŒ³ : 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb04284c80964c06b03f4f5a4a3becb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Constructing Tree...:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34032369f23b49f392de3ec2152504d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing path...:   0%|          | 0/28462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5 => Macro F1-Score: 0.506\n",
      "Threshold: 0.6 => Macro F1-Score: 0.558\n",
      "Threshold: 0.7 => Macro F1-Score: 0.552\n",
      "Threshold: 0.8 => Macro F1-Score: 0.5\n",
      "Threshold: 0.9 => Macro F1-Score: 0.5\n",
      "â­ï¸ Best F1-Score : 0.558\n"
     ]
    }
   ],
   "source": [
    "exp_ntrees = [10, 50, 100]\n",
    "exp_ntrees_results = {}\n",
    "exp_ntrees_forests = []\n",
    "for ntree in exp_ntrees:\n",
    "    print(\"=\"*100)\n",
    "    print(f'Number of ğŸŒ³ : {ntree}')\n",
    "    F = iForest(train_dataset, ntrees=ntree, sample_size=256)\n",
    "    S_val = F.compute_paths(X_in=val_dataset_attributes)\n",
    "    exp_ntrees_results[ntree] = S_val\n",
    "    exp_ntrees_forests.append(F)\n",
    "    show_result(S_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e9f00cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adfadsfadf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56348/3235631355.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madfadsfadf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'adfadsfadf' is not defined"
     ]
    }
   ],
   "source": [
    "adfadsfadf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a3121",
   "metadata": {},
   "source": [
    "- **sample sizeì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d7b7176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Number of Sample Size : 128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711925b4facf4d4c9589febe92646e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Constructing Tree...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f975429d97024c54a562008bf3b5cc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing path...:   0%|          | 0/28462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5 => Macro F1-Score: 0.483\n",
      "Threshold: 0.6 => Macro F1-Score: 0.519\n",
      "Threshold: 0.7 => Macro F1-Score: 0.499\n",
      "Threshold: 0.8 => Macro F1-Score: 0.5\n",
      "Threshold: 0.9 => Macro F1-Score: 0.5\n",
      "â­ï¸ Best F1-Score : 0.519\n",
      "====================================================================================================\n",
      "Number of Sample Size : 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9227d52860aa4311ad1ee8c3fd1b4202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Constructing Tree...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f5942d75fe4efca7c452aad2d4a588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing path...:   0%|          | 0/28462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5 => Macro F1-Score: 0.5\n",
      "Threshold: 0.6 => Macro F1-Score: 0.554\n",
      "Threshold: 0.7 => Macro F1-Score: 0.614\n",
      "Threshold: 0.8 => Macro F1-Score: 0.5\n",
      "Threshold: 0.9 => Macro F1-Score: 0.5\n",
      "â­ï¸ Best F1-Score : 0.614\n",
      "====================================================================================================\n",
      "Number of Sample Size : 512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ec398b81f04249b539fa292ad35939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Constructing Tree...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad9bb4551ce4d65b8ba4116e55edf63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing path...:   0%|          | 0/28462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.5 => Macro F1-Score: 0.515\n",
      "Threshold: 0.6 => Macro F1-Score: 0.599\n",
      "Threshold: 0.7 => Macro F1-Score: 0.707\n",
      "Threshold: 0.8 => Macro F1-Score: 0.5\n",
      "Threshold: 0.9 => Macro F1-Score: 0.5\n",
      "â­ï¸ Best F1-Score : 0.707\n"
     ]
    }
   ],
   "source": [
    "exp_ss = [128, 256, 512]\n",
    "exp_ss_results = {}\n",
    "exp_ss_forests = []\n",
    "for ss in exp_ss:\n",
    "    print(\"=\"*100)\n",
    "    print(f'Number of Sample Size : {ss}')\n",
    "    F = iForest(train_dataset, ntrees=10, sample_size=ss)\n",
    "    S_val = F.compute_paths(X_in=val_dataset_attributes)\n",
    "    exp_ss_results[ss] = S_val\n",
    "    exp_ss_forests.append(F)\n",
    "    show_result(S_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8449c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b9e21e",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Non-random Split using Information gain\n",
    "> Information gainì„ í†µí•´ Decision Treeë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•´ì„œ í•„ìš”í•œ Label ì •ë³´ê°€ í˜„ì¬ Train Datasetì—ëŠ” ì—†ìœ¼ë¯€ë¡œ í•œë²ˆ í•™ìŠµì„ ì§„í–‰í•œ Isolation Forestë¥¼ í†µí•´ Pseudo Labelì„ êµ¬ì¶•í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "- Reference\n",
    "    - https://community.rapidminer.com/discussion/58166/decision-tree-without-a-label-is-it-possible\n",
    "    - https://towardsdatascience.com/entropy-and-information-gain-in-decision-trees-c7db67a3a293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fad4906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pseudo_label(dataset):\n",
    "    # ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ n_tree=10, sample_size=512ì˜ Isolation Forestë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "    S_train = exp_ss_forests[-1].compute_paths(X_in=train_dataset)\n",
    "    pseudo_label = np.where(S_train >= 0.7, 1, 0)\n",
    "    return pseudo_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c81604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_copy = train_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58709599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c945a5b50f400ebd67652e1f560e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing path...:   0%|          | 0/113842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset_copy['pseudo_label'] = get_pseudo_label(train_dataset_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c6cbad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_label = train_dataset_copy['pseudo_label']\n",
    "train_dataset_attributes = train_dataset_copy.drop(columns=['pseudo_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db510fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(column):\n",
    "    # Compute the counts of each unique value in the column\n",
    "    counts = np.bincount(column)\n",
    "    # Divide by the total column length to get a probability\n",
    "    probabilities = counts / len(column)\n",
    "    \n",
    "    # Initialize the entropy to 0\n",
    "    entropy = 0\n",
    "    # Loop through the probabilities, and add each one to the total entropy\n",
    "    for prob in probabilities:\n",
    "        if prob > 0:\n",
    "            # use log from math and set base to 2\n",
    "            entropy += prob * math.log(prob, 2)\n",
    "    \n",
    "    return -entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcce0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_information_gain(data, split_name, target_name='pseudo_label'):\n",
    "    # Calculate the original entropy\n",
    "    original_entropy = calc_entropy(data[target_name])\n",
    "    \n",
    "    #Find the unique values in the column\n",
    "    values = data[split_name].unique()\n",
    "    \n",
    "    # Make two subsets of the data, based on the unique values\n",
    "    left_split = data[data[split_name] == values[0]]\n",
    "    right_split = data[data[split_name] == values[1]]\n",
    "    \n",
    "    # Loop through the splits and calculate the subset entropies\n",
    "    to_subtract = 0\n",
    "    for subset in [left_split, right_split]:\n",
    "        prob = (subset.shape[0] / data.shape[0]) \n",
    "        to_subtract += prob * calc_entropy(subset[target_name])\n",
    "    \n",
    "    # Return information gain\n",
    "    return original_entropy - to_subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_info_gain(columns):\n",
    "    #Intialize an empty dictionary for information gains\n",
    "    information_gains = {}\n",
    "\n",
    "    #Iterate through each column name in our list\n",
    "    for col in columns:\n",
    "        #Find the information gain for the column\n",
    "        information_gain = calc_information_gain(midwest, col, \n",
    "        #Add the information gain to our dictionary using the column name as the ekey                                         \n",
    "        information_gains[col] = information_gain\n",
    "\n",
    "    #Return the key with the highest value                                          \n",
    "    return max(information_gains, key=information_gains.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb954b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class iTree(object):\n",
    "    def __init__(self, X, e, l):\n",
    "        self.e = e  # í˜„ì¬ tree height\n",
    "        self.X = X  # ë°ì´í„°\n",
    "        self.size = len(X) # ë°ì´í„°ì— í¬í•¨ëœ object ê°œìˆ˜\n",
    "        self.Q = np.arange(np.shape(X)[1], dtype='int') # ë°ì´í„°ì˜ attributes\n",
    "        self.l = l  # ì¢…ë£Œ ì¡°ê±´ì— ì‚¬ìš©ë  treeì˜ height limit\n",
    "        self.p = None  # split point (max(values of q), min(values of q) ì¤‘ ëœë¤í•˜ê²Œ ì„ íƒë¨)\n",
    "        self.q = None  # split attribute (Qì—ì„œ ëœë¤í•˜ê²Œ ì„ íƒë¨)\n",
    "        self.exnodes = 0  # external node\n",
    "        self.root = self.make_tree(X, e, l)\n",
    "        \n",
    "\n",
    "    def make_tree(self, X, e, l, split_criteria='random'):\n",
    "        self.e = e\n",
    "        \n",
    "        # ì¢…ë£Œ ì¡°ê±´\n",
    "        # 1. í˜„ì¬ tree heightì´ ì‚¬ì „ ì§€ì •í•œ height limitì— ë„ë‹¬í•œ ê²½ìš°\n",
    "        # 2. \n",
    "        if e >= l or len(X) <= 1:\n",
    "            left = None\n",
    "            right = None\n",
    "            self.exnodes += 1\n",
    "            return Node(X, self.q, self.p, e, left, right, node_type = 'exNode')\n",
    "        else:\n",
    "            # Splití•˜ëŠ” ê¸°ì¤€ì´ ë˜ëŠ” Attributeë¥¼ ë°ì´í„°ì˜ Attributes ì¤‘ì—ì„œ ëœë¤í•˜ê²Œ ì„ íƒ\n",
    "            self.q = random.choice(self.Q)\n",
    "            mini = X[:,self.q].min()\n",
    "            maxi = X[:,self.q].max()\n",
    "            if mini==maxi:\n",
    "                left = None\n",
    "                right = None\n",
    "                self.exnodes += 1\n",
    "                return Node(X, self.q, self.p, e, left, right, node_type = 'exNode' )\n",
    "            \n",
    "            # Split Pointë¥¼ min(values of q), max(values of q) ì¤‘ ëœë¤í•˜ê²Œ ì„ íƒ\n",
    "            self.p = random.uniform(mini, maxi)\n",
    "            \n",
    "            # qê°€ pë³´ë‹¤ ì‘ì€ ë°ì´í„°ë“¤ì€ left nodeë¡œ, qê°€ pë³´ë‹¤ ê°™ê±°ë‚˜ í° ë°ì´í„°ë“¤ì€ right nodeë¡œ ì§€ì •\n",
    "            # ìœ„ì™€ ê°™ì€ ê³¼ì •ë“¤ì„ ì¬ê·€ì ìœ¼ë¡œ ë¶„ê¸° ì§„í–‰\n",
    "            w = np.where(X[:, self.q] < self.p, True, False)\n",
    "            return Node(X, self.q, self.p, e,\\\n",
    "                        left=self.make_tree(X[w], e+1, l),\\\n",
    "                        right=self.make_tree(X[~w], e+1, l),\\\n",
    "                        node_type = 'inNode')\n",
    "\n",
    "    def get_node(self, path):\n",
    "        node = self.root\n",
    "        for p in path:\n",
    "            if p == 'L' : node = node.left\n",
    "            if p == 'R' : node = node.right\n",
    "        return node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade5e1b4",
   "metadata": {},
   "source": [
    "> ìœ íŠœë¸Œ ì˜ìƒì„ ì œì‘í•˜ë©´ì„œ ë“¤ì—ˆë˜ ê¶ê¸ˆì¦ì„ í•´ê²°í•  ìˆ˜ ìˆì—ˆë˜ ìœ ìµí•œ ì‹œê°„ì´ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ ë‹¤ìŒ íŠœí† ë¦¬ì–¼ì— **`Ensemble Learning`**ìœ¼ë¡œ ë‹¤ì‹œ ì°¾ì•„ëµ™ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "<img src=\"images/9_turtle.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86e6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
